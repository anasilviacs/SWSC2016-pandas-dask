{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NYC Taxi data\n",
    "In this notebook we use distributed dataframes to analyze NYC Taxi data (https://data.cityofnewyork.us/view/ba8s-jw6u, http://www.nyc.gov/html/tlc/html/about/trip_record_data.shtml)\n",
    "\n",
    "This data is stored as large CSV files on S3 in a public bucket (https://s3.amazonaws.com/nyc-tlc/trip+data/). We could load them using the `s3fs` library:\n",
    "\n",
    "    >>> from s3fs import S3FileSystem\n",
    "    >>> s3 = S3FileSystem(anon=True)\n",
    "\n",
    "    >>> s3.ls('nyc-tlc/trip data/')\n",
    "    [...\n",
    "     'nyc-tlc/trip data/yellow_tripdata_2009-01.csv',\n",
    "     ...\n",
    "     'nyc-tlc/trip data/yellow_tripdata_2015-01.csv',\n",
    "     'nyc-tlc/trip data/yellow_tripdata_2015-02.csv',\n",
    "     'nyc-tlc/trip data/yellow_tripdata_2015-03.csv',\n",
    "     'nyc-tlc/trip data/yellow_tripdata_2015-04.csv',\n",
    "     'nyc-tlc/trip data/yellow_tripdata_2015-05.csv',\n",
    "     'nyc-tlc/trip data/yellow_tripdata_2015-06.csv',\n",
    "     'nyc-tlc/trip data/yellow_tripdata_2015-07.csv',\n",
    "     'nyc-tlc/trip data/yellow_tripdata_2015-08.csv',\n",
    "     'nyc-tlc/trip data/yellow_tripdata_2015-09.csv',\n",
    "     'nyc-tlc/trip data/yellow_tripdata_2015-10.csv',\n",
    "     'nyc-tlc/trip data/yellow_tripdata_2015-11.csv',\n",
    "     'nyc-tlc/trip data/yellow_tripdata_2015-12.csv',\n",
    "     'nyc-tlc/trip data/yellow_tripdata_2016-01.csv',\n",
    "     'nyc-tlc/trip data/yellow_tripdata_2016-02.csv',\n",
    "     'nyc-tlc/trip data/yellow_tripdata_2016-03.csv',\n",
    "     'nyc-tlc/trip data/yellow_tripdata_2016-04.csv',\n",
    "     'nyc-tlc/trip data/yellow_tripdata_2016-05.csv',\n",
    "     'nyc-tlc/trip data/yellow_tripdata_2016-06.csv']\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To work with these, we did download some of them and put them on a data share. You can copy them to ``$VSC_SCRATCH_NODE`` (`/local`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to load this data with Pandas, but there is too much data here to fit in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.read_csv(\"/local/yellow_tripdata_2015-01.csv\", nrows=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we connect to the cluster and use dask.dataframe to load the CSV data into ~700 Pandas dataframes spread across our cluster.  We get back a Dask.dataframe to coordinate these small Pandas dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `dask.distributed` network consists of one `Scheduler` node and several `Worker` nodes. You connect to these with a `Client`. One can set these up in a variety of ways (https://distributed.readthedocs.io/en/latest/setup.html).\n",
    "\n",
    "If you create an client without providing an address it will start up a local scheduler and worker for you:\n",
    "\n",
    "    >>> from distributed import Client\n",
    "    >>> client = Client()\n",
    "    >>> client\n",
    "    <Client: scheduler=\"127.0.0.1:8786\" processes=8 cores=8>\n",
    "    \n",
    "You can also set up a network on the HPC cluster, and connect to it using the Scheduler's address:\n",
    "\n",
    "    >>> client = Client(\"10.141.18.78:8786\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from distributed import Client, progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = dd.read_csv(\"/local/yellow_tripdata_2015-01.csv\",\n",
    "                 parse_dates=['tpep_pickup_datetime', 'tpep_dropoff_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information about the current state of the network helps to track progress, identify performance issues, and debug failures.\n",
    "\n",
    "Dask.distributed includes a web interface to help deliver this information over a normal web page in real time. This web interface is launched by default wherever the scheduler is launched if the scheduler machine has Bokeh installed. The web interface is normally available at http://scheduler-address:8787/status/ and can be viewed any normal web browser.\n",
    "\n",
    "Connect over ssh to the 8787 port on the node you are working on, and see the web interface on: http://127.0.0.1:8787/status/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = client.persist(df)\n",
    "progress(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.passenger_count.sum().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.info(memory_usage=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play\n",
    "\n",
    "Existing Pandas experience transfers over decently well to Dask.dataframe.  However there are a few caveats when dealing with distributed systems:\n",
    "\n",
    "*  Until you call `client.persist` (for large results) or `client.compute` (for small results), all computations are lazy\n",
    "*  Call `progress` on a dataframe *after* you persist to track the progress of a computation.  You can continue doing work immediately.  All work happens in the background.\n",
    "*  If you are computing a small result, just add `.compute()` to the end of your result, like `df.passenger_count.sum().compute()`.  This will block and return the result when finished."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive_fares = df[df.fare_amount > 0]\n",
    "fares = df[['fare_amount', 'tip_amount', 'payment_type']]\n",
    "\n",
    "fares = client.persist(fares)  # triggers computation\n",
    "progress(fares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fares.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(fares.tip_amount == 0).sum().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fares.count().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.passenger_count.sum().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>: \n",
    "    \n",
    "Compute the following using `.compute()`:\n",
    "\n",
    "<ul>\n",
    "<li>The mean of the passenger count column</li>\n",
    "<li>The mean trip distance grouped by passenger count</li>\n",
    "</ul>\n",
    "\n",
    "<p>Create a new dataframe that filters out all the rides greater than three miles, then compute the above quantities again.  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the time as index\n",
    "\n",
    "Use the `.set_index` method to set the index to the `tpep_pickup_datetime` column.  This is an *expensive* operation, so call `client.persist` on the result to create a new dataframe that is persisted in distributed memory.  Use the `progress` function to track the progress.\n",
    "\n",
    "Once this finishes you have access to datetime functionality like `loc`, `resample` and `rolling` aggregations.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = df.set_index('tpep_pickup_datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = client.persist(df2)\n",
    "progress(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dask dataframe now has divisions, making certain operations much more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.divisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2.divisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>: Plot the hourly number of taxi trips for Jan 1 to Jan 5\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>: Plot daily profile of number of taxi trips\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>: Plot the daily tip average\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>: Based on the previous result: Is there a week pattern within the avarage tip amount?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>: For those trips were a tip has been given, calculate the tip fraction (tip_amount / fare_amount) and calculate the daily profile of this fraction.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## More data\n",
    "\n",
    "Up to now we performed the analyses on one of the csv files: all data for January 2015. You can repeat the notebook with multiple of the files:  \n",
    "\n",
    "    df = dd.read_csv(\"/local/yellow_tripdata_2015-*.csv\",\n",
    "                     parse_dates=['tpep_pickup_datetime', 'tpep_dropoff_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
